---
title: "DADA2_Ejemplo_Clase"
author: "Roberto Álvarez"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    html_document: 
      fig_height: 8
      fig_width: 13
      number_section: yes
      theme: cerulean
      toc: yes
      toc_float:
        collapsed: no
        smooth_scroll: yes
---
First, we need to make sure the first steps to make easier the work flow are in place. In these steps we load the library *dada2*.
```{r message=FALSE, warning=FALSE}
library(dada2)#load the necessary library
```

Now, we define the path in order to get the FASTQ files we already have, since we'll be using all of them.
```{r}
path <- "~/R/Genomica_funcional/DADA2_Ejemplo_Clase/MiSecuenciasAqui/" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
#shows the archives and files in the path that was just previously defined
```

Next, the we will separate the files based on wether they're the forward or the reverse strand. In this particular case, the forward strands will be those assigned with *R1* within their name, meanwhile, the reverse strands will be those with *R2* instead. 
```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
#In this step we are assigning the files either to the forward or the reverse so that they are separated
#MUST WRITE THE FULL PATH
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)

```

## Calidad phred
In this part, the function *plotQualityProfile* will plot the qualities that were assigned in the FASTQ files, so we'll have a visual representation of the quality and where we would want the trimming to be done.
```{r}
plotQualityProfile(fnFs[1:2])
```

```{r}
plotQualityProfile(fnRs[1:2])
```


## Filtrado y trimming
The following part will be used for the filtering and the trimming of the files, since we won't be using the sequences which quality is below a certain threshhold.
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))#criteria for the outing
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
#the filtered files will be within the file called 'filtered', they are once again separated between the forward and reverse strands
names(filtFs) <- sample.names
names(filtRs) <- sample.names
#we are just assingning the names of the files, may look like they arte the same, but it's because it is the first part of the name, nbot whole
```


```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160), #first is the path of the forward fastq file, 
                                                                      #then the path for the filtered filed; then same but with reverse strand
                                                   #the argument trunclen sets a threshold for the length of each of the strains' reads length
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, #maxN: after being truncated, any sequences with a higher Ns than what it is stated
                                                            #won't be used
                                                            #maxEE: after truncation, reads with higher than maxEE "expected errors" will be discarded
                                                            #truncQ: Truncate reads at the first instance of a quality 
                                                            #score less than or equal to truncQ.
                                                            #rm.phix:  discard reads that match against the phiX genome, as determined by isPhiX if T
              compress=TRUE, multithread=F) # On Windows set multithread=FALSE
                                            #compress: the output fastq file(s) are gzipped if it is True
#the output of the function above has an output of fastq file(s) (compressed by default) containing those trimmed reads which passed the filters
#CHECK THE DOCUMENTATION 
head(out)
```


## Filtrado y tasas de error
Will use the filtered files, meaning those that have already been cut in order for us to be content with the quality and are good enough for our work.
```{r}
#errF <- learnErrors(filtFs, multithread=TRUE) didn't do it to save time, but this line is to make it
load(file="errF.RData")
#more or less will estimate via machine laerning what would be expected and the observed data, compares and calculates the error
#Error rates are learned by alternating between sample inference and error rate estimation until convergence
#output of this function serves as input to the dada function call as the err parameter.
#save(errF,file="~/Dropbox/DADA2_Ejemplo_Clase/errF.RData")
```


```{r}
#errR <- learnErrors(filtRs, multithread=TRUE)
load("errR.RData")
#more or less will estimate via machine laerning what would be expected and the observed data, compares and calculates the error
#Error rates are learned by alternating between sample inference and error rate estimation until convergence
#output of this function serves as input to the dada function call as the err parameter.
#save(errR,file="~/Dropbox/DADA2_Ejemplo_Clase/errR.RData")
```


```{r}
plotErrors(errF, nominalQ=TRUE)
#this will plot  the observed frequency of each transition (eg. A->C) as a function of the associated quality score
```


## Inferencia de la muestra



```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
#this function will remove sequencing errors, that is why we calculated the error, and will reveal the composition of the community
#save(dadaFs, file="~/Dropbox/DADA2_Ejemplo_Clase/dadaFs.RData")
```

```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
#this function will remove sequencing errors, that is why we calculated the error, and will reveal the composition of the community
#save(dadaRs, file="~/Dropbox/DADA2_Ejemplo_Clase/dadaRs.RData")
```


```{r}
dadaFs[[1]]#an example of the data that is gathered when using the dada function, 128 sequence variants in this one, for example
```


## Merge paired reads



```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
#will merge the reads of both senses, the noise has been removed, thats is why it is called "denoised". It rejects pairs that don't overlap sufficiently or contains many 0's by mismatches while overlapping, it has the forward dada and the forward filtered files, same but with reverse
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```


## Construir la tabla de secuencias

```{r}
seqtab <- makeSequenceTable(mergers)#This function constructs a sequence table (analogous to an OTU table) from the provided list of samples.
dim(seqtab)#there were 20 total mergers since there were 20 fastq files for reverse and 20 for forward each amounts for 293 sequences
```


## Remover quimeras


```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)#after denoising, the chimeras are left and can be identfified so that they can be removed, for example, with this funcion. The chimeras are 2 sequences that were incorrectly joined together. The method makes it so that only thetable that is provided wil be affected
dim(seqtab.nochim)#there were 20 total mergers since there were 20 fastq files for reverse and 20 for forward, each amounts for 232 sequences
```

```{r}
sum(seqtab.nochim)/sum(seqtab)#if done correctly, most of the sequences (almost a 1), should remain, if not, the process and steps upstream should be revised for any kind of error
```


## Verificar el número de lecturas después del pipeline


```{r}
getN <- function(x) sum(getUniques(x))#i gues this line will get the unique seuqences, meaning vectors from the objects, meaning the sequences.
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))#this should get us the reads and the unique sequences we had at the beginning and at each step; since it looks like it hasn't dropped o much, it is fine
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

  
## Asignar taxonomía

Hay que descragar las bases de datos más actualizada acá en la siguiente liga (Taxonomic reference data)[https://benjjneb.github.io/dada2/training.html] . Los archivos que descargan son dos: silva_nr_v132_train_set.fa.gz y 

Estos dos procesos pueden tardar mucho, cuidado


```{r}
taxa <- assignTaxonomy(seqtab.nochim,"~/R/Genomica_funcional/DADA2_Ejemplo_Clase/tax/silva_nr_v132_train_set.fa.gz", multithread=T) #it could be done, and tried to load it, but it just wouldn't find the file even though files from thesame file had been loaded in the same fashion
#apparently, this function starts assigning the taxonomy to to the sequence variants given the amplicon used and a series of training sequences with known taxonomy so that it may assign correctly the sequences that we gave
#save(taxa,file="~/Dropbox/DADA2_Ejemplo_Clase/taxa1.RData")
load("~/R/Genomica_funcional/DADA2_Ejemplo_Clase/taxa1.RData")
```


```{r}
taxa <- addSpecies(taxa,"~/R/Genomica_funcional/DADA2_Ejemplo_Clase/tax/silva_species_assignment_v132.fa.gz")
#this part has the ability to assign the species to each sequence, but only f they are a perfect match and fulfill certain criteria like genera classification and the sort; for more info, check the documentation
#save(taxa,file="~/Dropbox/DADA2_Ejemplo_Clase/taxa.RData")
load("~/R/Genomica_funcional/DADA2_Ejemplo_Clase/taxa.RData")
```

```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL#the names were the full sequences, so not very helpful
head(taxa.print)#now it says the taxonomy rather than the full sequence and the taxonomy
```

### Alternativas (OPCIONAL)

```{r}
# Si no tienen instalado esta librería pueden hacerlo
BiocManager::install("DECIPHER")
library(DECIPHER); packageVersion("DECIPHER")
```

NO EJECUTAR SI NO TIENES BIEN INSTALADO DECIPHER

```{r}
dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs
load("~/R/Genomica_funcional/DADA2_Ejemplo_Clase/tax/IDTaxa/SILVA_SSU_r132_March2018.RData") # CHANGE TO THE PATH OF YOUR TRAINING SET, don't really know what i loaded
ids <- IdTaxa(dna, trainingSet, strand="top", processors=NULL, verbose=FALSE) # use all processors, it is classifying the sequences into the taxonomic labels, has to work with string sequences, a trainingset to classify
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species") # ranks of interest
# Convert the output object of class "Taxa" to a matrix analogous to the output from assignTaxonomy
taxid <- t(sapply(ids, function(x) {
        m <- match(ranks, x$rank)
        taxa <- x$taxon[m]
        taxa[startsWith(taxa, "unclassified_")] <- NA
        taxa
}))#Once again, this steps is used to have the taxonomy of the sequences without any innecesary data
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(seqtab.nochim)#Assigns the name of the row the complete sequence, while the columns are the info that was generated 
```


## Evaluar precisión


```{r}
unqs.mock <- seqtab.nochim["Mock",]#shows the read count of each sequence in this specific file
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock, meaning those with no reads
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")#this tells us apparently there are 20 strains identified in the mock community
```



```{r}
mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))#extracts sequences from the objects and tells us from the mock sample how many sequences from distinct organisms it got
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")#every match was same as the 20 bacterial reference strains, therefore the residual error is 0%

```


## Convertir a phyloseq

```{r message=FALSE, warning=FALSE}
#load more necessary libraries
library(phyloseq); packageVersion("phyloseq")
library(Biostrings); packageVersion("Biostrings")
library(ggplot2); packageVersion("ggplot2")
```


```{r}
theme_set(theme_bw())#it is just making the theme for every plot that will come to be from this point onwards
```

Construct a data frame from the information n the filenames
```{r}
samples.out <- rownames(seqtab.nochim)#nanmes of the filtered and then merged files
subject <- sapply(strsplit(samples.out, "D"), `[`, 1)#will cut the name if a "D" is present
gender <- substr(subject,1,1)#extracts a character, since it is the first one, it seems as if it was from genders "F" and "M"
subject <- substr(subject,2,999)#will extact all the characters except the first one of all the names, so it gives a number for each file, except the mock
kk<-sapply(strsplit(samples.out, "D"), `[`, 2)
day <- as.integer(sapply(strsplit(kk, "_F"), `[`, 1))#makes a split in the letter D, then only takes the second part of the split and then takes it as integer
samdf <- data.frame(Subject=subject, Gender=gender, Day=day)#makes a data frame from the data
samdf$When <- "Early"#creates another column
samdf$When[samdf$Day>100] <- "Late"#doesn't really apply, don't know when it woul be higher than 100
rownames(samdf) <- samples.out#just renames to the file names
```



```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), #this will generate a phlyoseq object from an otu table made from the non-chimeric files
               sample_data(samdf), #access the sample data, in this case, the data frame we created just recently
               tax_table(taxa))#recommended way to construct a table with taxonomic names
ps <- prune_samples(sample_names(ps) != "Mock_F_filt.fastq.gz", ps) # Remove mock sample
```



```{r}
dna <- Biostrings::DNAStringSet(taxa_names(ps))#will take the sequence as the taxa names, and then will take thos sequences as dna strings so we don't lose info
names(dna) <- taxa_names(ps)#the names are the sequences
ps <- merge_phyloseq(ps, dna)#i guess it will merge the objects we created into one with the all the information
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))#assigned ASV and simply numbered, those are the new taxa names
ps
```

# Al fin deiversidad

```{r}
plot_richness(ps, x="Day", color="When") #plots the alpha diversity, it estimates with different indexes the diversity

```


# Algunas medidas de reducción de la dimensionalidad

```{r}
# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))#transforms the sample counts of a taxa abundance matrix according to a user-provided function
ord.nmds.bray <- ordinate(ps.prop, method="NMDS", distance="bray")#Didn't really get it
```

```{r}
plot_ordination(ps.prop, ord.nmds.bray, color="When", title="Bray NMDS")
```


# Gráficos de barras apiladas de abundancias

```{r}
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="Day", fill="Family") + facet_wrap(~When, scales="free_x")
```

